{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dafedb9a-cf4f-4500-aa14-edbb19540de0",
   "metadata": {},
   "source": [
    "# Example Notebook Running SPARCSpy on datasets with multiple images\n",
    "\n",
    "The SPARCSpy base Project class is focused on processing whole slide images. In case you want to process Image Datasets with multiple-images then you will need to use the SPARCSpy TimecourseProject class and associated methods. This tutorial will walk you through this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e7032-5134-4a41-b9f6-5f0f62f82b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sparcscore.pipeline.classification import CellFeaturizer\n",
    "from sparcscore.pipeline.extraction import TimecourseHDF5CellExtraction\n",
    "from sparcscore.pipeline.project import TimecourseProject\n",
    "from sparcscore.pipeline.workflows import Multithreaded_Cytosol_Cellpose_Downsampling_TimecourseSegmentation\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d269ba93-a4f8-4e4c-aaa3-6523695e8004",
   "metadata": {},
   "source": [
    "## Some Helper Functions for visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c5d00-4cde-4590-98a0-16f0bcfd0903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparcscore.processing.preprocessing import percentile_normalization\n",
    "\n",
    "\n",
    "def plot_seg_overlay_timecourse(project_path, channel_to_show=0, seg_mask_to_show=0, selection=None, return_fig=False):\n",
    "    seg_path = f\"{project_path}/segmentation/input_segmentation.h5\"\n",
    "    with h5py.File(seg_path, \"r\") as hf:\n",
    "        segmentation = hf.get(\"segmentation\")\n",
    "        channels = hf.get(\"input_images\")\n",
    "\n",
    "        print(segmentation)\n",
    "        print(channels)\n",
    "\n",
    "        if selection is None:\n",
    "            segmentation = segmentation[0, seg_mask_to_show, :, :]\n",
    "            image = channels[0, channel_to_show, :, :]\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.imshow(percentile_normalization(image), cmap=\"Greys_r\")\n",
    "            plt.imshow(segmentation, alpha=0.5, cmap=\"jet\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        if return_fig:\n",
    "            return fig\n",
    "\n",
    "\n",
    "def visualize_single_cells(project_path, n_cells=10):\n",
    "    cells_path = f\"{project_path}/extraction/data/single_cells.h5\"\n",
    "\n",
    "    with h5py.File(cells_path, \"r\") as hf:\n",
    "        cells = hf.get(\"single_cell_data\")\n",
    "        n_channels = cells.shape[1]\n",
    "\n",
    "        fig, axs = plt.subplots(n_cells, n_channels, figsize=(n_channels * 1, n_cells * 1))\n",
    "\n",
    "        for i in range(n_cells):\n",
    "            image = cells[i]\n",
    "            for n in range(n_channels):\n",
    "                axs[i, n].imshow(image[n])\n",
    "                axs[i, n].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565c7e0-f6d4-46c0-b81e-5c1f362a4b66",
   "metadata": {},
   "source": [
    "## Initialize a Project\n",
    "\n",
    "SPARCSpy works with a project structure that is kept the same across different projects. Each project contains all of the results from one run. Each Project has the same general structure:\n",
    "\n",
    "    .\n",
    "    ├── classification\n",
    "    │   └── classifier_name\n",
    "    │       └── processing.log\n",
    "    ├── config.yml\n",
    "    ├── extraction\n",
    "    ├── segmentation\n",
    "    └── processing.log\n",
    "\n",
    "\n",
    "At the beginning of a SPARCSpy analysis a new project is generated where configuration parameters are loaded from the config file. This determines how each processing step will be executed.Here is a minimal example including the different cellpose segmentation methods for TimecourseProjects.\n",
    "\n",
    "    ----------------\n",
    "    name: \"HPA segmentation\"\n",
    "    input_channels: 3\n",
    "    output_channels: 5 #always add 2 to the number of channels\n",
    "    Multithreaded_Cytosol_Cellpose_TimecourseSegmentation:\n",
    "        input_channels: 3\n",
    "        output_masks: 2\n",
    "        threads: 5 #the segmentation model is loaded for each segmentation process utilizing GPU memory. Depending on GPU size this needs to be adjusted\n",
    "        cache: \".\" #path to where intermediate results are written to memory mapped temp arrays\n",
    "        lower_quantile_normalization:   0.000\n",
    "        upper_quantile_normalization:   1.000\n",
    "        median_filter_size:   4 \n",
    "        nucleus_segmentation:\n",
    "            model: \"nuclei\"\n",
    "            diameter: 400 #if this parameter is not set then cellpose will determine the diameter of the segemented shapes automatically\n",
    "        cytosol_segmentation:\n",
    "            model: \"cyto2\"\n",
    "            diameter: 700\n",
    "        chunk_size: 50\n",
    "        match_masks: True\n",
    "        filtering_threshold_mask_matching: 0.95\n",
    "        filter_masks_size: False\n",
    "    Multithreaded_Cytosol_Cellpose_Downsampling_TimecourseSegmentation:\n",
    "        input_channels: 3\n",
    "        output_masks: 2\n",
    "        threads: 5\n",
    "        cache: \".\"\n",
    "        lower_quantile_normalization:   0.000\n",
    "        upper_quantile_normalization:   1.000\n",
    "        median_filter_size:   4 \n",
    "        nucleus_segmentation:\n",
    "            model: \"nuclei\"\n",
    "        cytosol_segmentation:\n",
    "            model: \"cyto2\"\n",
    "        chunk_size: 50\n",
    "        match_masks: True\n",
    "        filtering_threshold_mask_matching: 0.95\n",
    "        filter_masks_size: False\n",
    "        downsampling_factor: 10 #downsamples images before performing segmentation, the segmented masks are upscaled again to the original dimension\n",
    "        smoothing_kernel_size: 7\n",
    "    Cytosol_Cellpose_Downsampling_TimecourseSegmentation:\n",
    "        input_channels: 3\n",
    "        output_masks: 2\n",
    "        cache: \".\"\n",
    "        lower_quantile_normalization:   0.000\n",
    "        upper_quantile_normalization:   1.000\n",
    "        median_filter_size:   4 \n",
    "        nucleus_segmentation:\n",
    "            model: \"nuclei\"\n",
    "        cytosol_segmentation:\n",
    "            model: \"cyto2\"\n",
    "        chunk_size: 50\n",
    "        match_masks: True\n",
    "        filtering_threshold_mask_matching: 0.95\n",
    "        filter_masks_size: False\n",
    "        downsampling_factor: 10\n",
    "        smoothing_kernel_size: 7\n",
    "    TimecourseHDF5CellExtraction:\n",
    "        compression: True\n",
    "        threads: 8 # threads used in multithreading\n",
    "        image_size: 512 # image size in pixel\n",
    "        cache: \".\"\n",
    "        hdf5_rdcc_nbytes: 5242880000 # 5gb 2048 * 2048 * 1250\n",
    "        hdf5_rdcc_w0: 1\n",
    "        hdf5_rdcc_nslots: 1250\n",
    "    CellFeaturizer:\n",
    "        channel_classification: 4\n",
    "        threads: 20 \n",
    "        batch_size: 100\n",
    "        dataloader_worker_number: 5\n",
    "        inference_device: \"cuda\"\n",
    "        screen_label: \"featurization_Ch4\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db1d0b3-c027-4827-b8c2-d09c944d9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize project\n",
    "project_location = \"project\"\n",
    "\n",
    "project = TimecourseProject(\n",
    "    os.path.abspath(project_location),\n",
    "    config_path=\"config_example6.yml\",\n",
    "    segmentation_f=Multithreaded_Cytosol_Cellpose_Downsampling_TimecourseSegmentation,\n",
    "    extraction_f=TimecourseHDF5CellExtraction,\n",
    "    classification_f=CellFeaturizer,\n",
    "    overwrite=False,\n",
    "    debug=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66e978-e393-40e8-a4ce-2b12cd264a45",
   "metadata": {},
   "source": [
    "## Input Data Format\n",
    "\n",
    "SPARCSpy was optimized to work with Data generated using an Opera Phenix Microscope. Each Project class has several data_loader functions associated with it that can be used to load data from different sources. You can find the code under `src/sparcscore/project.py`. The Dataloaders that load images from files are optimzied for file_name notation generated by the Phenix and the associated processing scripts. \n",
    "\n",
    "Data Format for `load_input_from_files`:\n",
    "\n",
    "    .... main directory\n",
    "        - Row02_Well02_Row02_Well02\n",
    "            - Timepoint001_Row02_Well02_Alexa488_zstack001Row02_Well02.tif\n",
    "            - Timepoint001_Row02_Well02_mCherry_zstack001_r000_c000.tif\n",
    "            - Timepoint001_Row02_Well02_DAPI_zstack001_r000_c000.tif\n",
    "        - ...\n",
    "\n",
    "Alternatively you can load data from a numpy array using `load_input_from_array` which can be used more flexibly to write your own dataloader:\n",
    "\n",
    "- images needs to be supplied in the shape (N, C, X, Y) to the parameter img\n",
    "- labels need to be supplied as a tidy dataframe to the parameter label. The first two columns of the dataframe need to contian the following information: row_index, unique Image ID. Then you can append as many additional labels as you want. \n",
    "\n",
    "Also feel free to submit a PR with a new dataloader for a common microscopy file format. Here we will demonstrate loading data using numpy to be more flexible to all data inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ae3c0-a206-4423-9599-900c44a09e60",
   "metadata": {},
   "source": [
    "## Example loading data via a numpy array\n",
    "\n",
    "the timecourse SPARCSpy project expects images of the following format: NCYX.\n",
    "\n",
    "All of the images need to have the same dimensions and the same number of channels. The channels should be in the following order: nucleus, cytosol, other channels. \n",
    "\n",
    "The images need to have the dtype uint16.\n",
    "\n",
    "Here we have example code which reads RGB images (saved as PNGs), converts them to the expected format and loads them into a SPARCSpy timecourse project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3e730-7e5e-4c0b-bd7d-c27c3f928be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metadata of images\n",
    "metadata = pd.read_csv(\"metadata.csv\", index_col=0)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2eb63-37d6-4745-aa7f-ce1a54122959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read images\n",
    "import platform\n",
    "from multiprocessing import Pool, get_context\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "image_paths = metadata[\"image_location\"]\n",
    "\n",
    "\n",
    "# define a function to read the images, they need to be return as image stacks with each channel in a different dimension of the type np.uint16\n",
    "def read_image(img):\n",
    "    image = plt.imread(img)\n",
    "    # convert from rgb to brg (nucleus, cytosol, other)\n",
    "    image = np.roll(image, 1, 2)\n",
    "    if image.shape[0] != 2048:\n",
    "        image = resize(\n",
    "            image, (2048, 2048)\n",
    "        )  # some of the images have different shapes so we force resize of those images that dont match the most common shape\n",
    "\n",
    "    # convert from H x W x C to C x H x W\n",
    "    image = np.moveaxis(image, [2, 0, 1], [0, 1, 2])\n",
    "    image = image.astype(\"float64\")\n",
    "    image = (image / image.max() * 65535).astype(\n",
    "        \"uint16\"\n",
    "    )  # normalize all images to the same range and then convert to uint16\n",
    "    return image\n",
    "\n",
    "\n",
    "context = \"spawn\" if platform.system() == \"Windows\" else \"fork\"\n",
    "\n",
    "with get_context(context).Pool(processes=12) as pool:\n",
    "    images = pool.map(read_image, image_paths)\n",
    "    images = np.stack(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d35b09-7972-4594-bf3d-9f4741a598e4",
   "metadata": {},
   "source": [
    "The images have the expected shape (10 images, 3 channels, 2048px, 2048px) and look as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ecb8c-ab45-4a29-8f51-fcfb7efd2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.shape)\n",
    "print(images.dtype)\n",
    "\n",
    "for i in images[0:3]:\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    axs[0].imshow(i[0])\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(i[1])\n",
    "    axs[1].axis(\"off\")\n",
    "    axs[2].imshow(i[2])\n",
    "    axs[2].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792158f-aad4-4f21-afc7-ed8fb5ad8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the metadata to the expected format\n",
    "metadata = metadata.reset_index()\n",
    "metadata = metadata.get(\n",
    "    [\"index\", \"image_URL\", \"gene_id\", \"antibody\", \"species\", \"cell_line\", \"organ\", \"cellosaurusID\"]\n",
    ")  # here we use the image_URL as a unqiue image id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348db68c-1972-4fde-b459-cf6009288f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into sparcspy\n",
    "project.load_input_from_array(images, label=metadata, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c9f4e",
   "metadata": {},
   "source": [
    "Images and labels are written to the `input_segmentation.h5` HDF5 file contained under segmentation in the project folder.\n",
    "The input images are written to the container \"input_images\" and the labels to \"labels\". Column names are saved in a seperate dataset with the name \"label_names\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f\"{project_location}/segmentation/input_segmentation.h5\") as hf:\n",
    "    print(hf.get(\"input_images\"))\n",
    "    print(hf.get(\"labels\"))\n",
    "\n",
    "    print(\"Example Label Dataset\")\n",
    "    print(hf.get(\"label_names\")[:])\n",
    "    print(hf.get(\"labels\")[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea4f3dc-86f4-4319-b2a8-9a51b91c7b00",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "SPARCSpy has different segmentation workflows between which you can choose. If you run a timecourse project you will need to also select a timecourse segementation method. \n",
    "\n",
    "**notes on cellpose segmentation methods:**\n",
    "\n",
    "Cellpose currently does not allow for the processing of image batches. Each image will thus be segmented individually on the GPU. In case you have large images this isnt an issue since the GPU is still fully utilzed (the sharding parameter can be used to set an optimal shard size for maximizing GPU utilization). For a large quantity of small images this leads to a very inefficient processing. To improve the speed a bit you can try running with multiple threads. Each thread will also load the model though so it requires quite some Memory overhead. This is hopefully an issue we can address in future releases. If its something you would like to work on get in touch with the developers we are happy for help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1658cd46-e514-4d51-b135-bde0020d3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.segment(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b5be33-501e-4047-898f-2f976ed3738e",
   "metadata": {},
   "source": [
    "Segmentation results are written to the `input_segmentation.h5` HDF5 file in a new data container called \"segmentation\". \n",
    "In addition a csv file called classes.csv is generated which contains all the cell_ids that are not located in image edges and will be further processed.\n",
    "\n",
    "If we look at the segmentation dataset we can see that it contains a numpy array containing two segmentation masks for each input image: the nuclear segmentation and the cytosol segmentation generated by our chosen segmentation method. If you use the method CytosolOnly both of the masks will be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac930d-ae5c-4e4b-a0e6-36947fd2e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seg_overlay_timecourse(project_location, channel_to_show=0)\n",
    "plot_seg_overlay_timecourse(project_location, channel_to_show=1)\n",
    "\n",
    "plot_seg_overlay_timecourse(project_location, channel_to_show=0, seg_mask_to_show=1)\n",
    "plot_seg_overlay_timecourse(project_location, channel_to_show=1, seg_mask_to_show=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b16ee3b-c3e3-478d-937f-c8e7764a6ce5",
   "metadata": {},
   "source": [
    "## Single-Cell Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2d1b0-f9d1-455c-a7a9-28434441c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27e89d-7e9a-42e3-aff5-b4e0fb0a5897",
   "metadata": {},
   "source": [
    "The extracted single-cell images are written to a h5py file single_cells.h5 located under `extraction\\data` within the project folder.\n",
    "\n",
    "The file contains four datasets: `single_cell_data`, `single_cell_index`, `single_cell_index_labelled`, `label_names`. \n",
    "\n",
    "`single_cell_data` contains the extracted single cell images while `single_cell_index` contains the cell id of the extracted cell at that location.\n",
    "\n",
    "The other two datacontainers integrated the labels from the base dataset and attach them to each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38171e2-3de8-4aec-b59f-4ccf37172985",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f\"{project_location}/extraction/data/single_cells.h5\") as hf:\n",
    "    print(hf.keys())\n",
    "\n",
    "    print(hf.get(\"label_names\")[:])\n",
    "    print(hf.get(\"single_cell_index_labelled\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cfbc56-6356-42cb-b6a5-a256bba01b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single cell index contains two columns, the first is the index position in the hdf5 datacontainer, the second is the cell id\n",
    "\n",
    "with h5py.File(f\"{project_location}/extraction/data/single_cells.h5\") as hf:\n",
    "    # print(hf[\"single_cell_index\"][0:10])\n",
    "    print(hf[\"single_cell_index\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bc0b6-799e-4926-96f2-56d0b0c7b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single cell index labelled contains the same information as single_cell_index\n",
    "# in the first two columns but adds additional columns with labelling information, the column names for\n",
    "# the labelling information is contained in label_names\n",
    "\n",
    "with h5py.File(f\"{project_location}/extraction/data/single_cells.h5\") as hf:\n",
    "    print(hf[\"label_names\"][:])\n",
    "    print(hf[\"single_cell_index_labelled\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd824f9-c6a7-41a7-92d0-878963a5a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_single_cells(project_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be16c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPARCSspatial-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
