{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning single-cell image extraction\n",
    "\n",
    "In this notebook we will look at how the specific values chosen to configure the single-cell extraction step will effect the generated single-cell images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scportrait\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scportrait.pipeline.extraction import HDF5CellExtraction\n",
    "from scportrait.pipeline.project import Project\n",
    "from scportrait.pipeline.segmentation.workflows import CytosolSegmentationCellpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate segmentation masks for use during single-cell extraction\n",
    "\n",
    "First we will create our scPortrait project, load the input images and generate a segmentation that we will use for subsequent single-cell extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_location = \"project_extraction_config\"\n",
    "\n",
    "config_path = scportrait.data.get_config_file(config_id = \"dataset_1_config\")\n",
    "\n",
    "project = Project(\n",
    "    os.path.abspath(project_location),\n",
    "    config_path=config_path,\n",
    "    overwrite=True,\n",
    "    debug=False,\n",
    "    segmentation_f=CytosolSegmentationCellpose,\n",
    "    extraction_f=HDF5CellExtraction,\n",
    ")\n",
    "\n",
    "dataset_7_path = scportrait.data.dataset_7()\n",
    "images = [f\"{dataset_7_path}/Ch1.tif\", f\"{dataset_7_path}/Ch2.tif\", f\"{dataset_7_path }/Ch3.tif\", f\"{dataset_7_path }/Ch4.tif\"]\n",
    "project.load_input_from_tif_files(images, channel_names=[\"Hoechst\", \"Cellmembrane\", \"marker1\", \"marker2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen input images are from a dataset where we have two stains with very different behaviour. The first (`marker1`) appears in all cells. For this stain we are mainly interested in differences in spatial distribution of the marker but not absolute expression levels. The second stain (`marker2`) is a selective stain that only appears in some of the cells. Here we are interested in both spatial distribution as well as relative differences in expression levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.plot_input_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During Segmentation its important that we use channels that show homogenous expression over all cells. Otherwise we would be introducing bias during the segmentation step already and selecting only specific cells. \n",
    "\n",
    "By using scPortrait's `CytosolSegmentationCellpose` we are already only selecting those cells where we have a clear matching between nucleus and cytosol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.segment()\n",
    "project.plot_segmentation_masks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract single cell-images\n",
    "\n",
    "Now we are going to extract single-cell images using the same input segmentation mask, but each time modifying one of the configuration parameters of the Extraction workflow. \n",
    "\n",
    "We will look at the effects of the two most important parameters:\n",
    "1. [`image_size`](#image-size)\n",
    "2. [`normalize_output`](#choosing-normalization-method)\n",
    "3. [`normalization_range`](#normalization-range)\n",
    "\n",
    "And also investigate how we can fine-tune the normalization step to our specific use case. To improve computation we will only extract 2 cells for each configuration using the `partial` key during during the workflow call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Size\n",
    "\n",
    "We will look at three different values for the parameter `image_size` and visualize the extracted single-cell images for each setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sizes = [50, 100, 200]\n",
    "for image_size in image_sizes:\n",
    "    project.config[\"HDF5CellExtraction\"][\"image_size\"] = image_size\n",
    "    project._update_extraction_f(HDF5CellExtraction)\n",
    "    project.extract(partial=True, n_cells=2, seed = 92)\n",
    "\n",
    "    fig = project.plot_single_cell_images(cell_ids=[80, 105], return_fig=True)\n",
    "    fig.suptitle(f\"Image size: {image_size}\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, image_size controls the size of the bounding box that is used to get the single-cell information from the dataset. Too small values for this parameter and the cells will be cutoff with information from their periphary missing. Too large values and our single-cell image datasets will largely consit of black pixels. \n",
    "\n",
    "This parameter will have to be configured based on the size of the cells you are imaging as well as the magnification at which the images are recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Normalization\n",
    "\n",
    "All single-cell images generated by scPortrait are rescaled to the \\([0, 1]\\) range in preparation for downstream deep learning applications.\n",
    "\n",
    "There are two approaches to how this normalization can occur:\n",
    "\n",
    "1. Relative differences in the dataset are preserved:\n",
    "\n",
    "   ```python\n",
    "   img = img / max(dtype)\n",
    "   ```\n",
    "\n",
    "2. each cell is individually rescaled to\n",
    "\n",
    "    ```python\n",
    "    img = img - np.quantile(img, x) / np.quantile(img, y)\n",
    "    ```\n",
    "\n",
    "You are able to further customize method 2 by customizing the chosen quantiles for the normalization.\n",
    "\n",
    "Which type of normalization method you should choose is highly dataset specific.\n",
    "\n",
    "If you are working with cell selective stains (e.g. because you want to identifiy specific celltypes) then it is recommended to turn of the percentile normalization.\n",
    "\n",
    "In contrast, if you are working with stains where you are only interested in the different spatial distribution of the marker of interest (e.g. because you are using an engineered cell line expressing a fluorescently tagged protein or general cell staining protocols like cell painting) then using the percentile normalization is recommended as it will help mitigate batch effects resulting from different concentrations of utilized cellstains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing normalization method\n",
    "\n",
    "The normalization method can be chosen via the parameter `normalize_output`. This configures which of the two methods is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.config[\"HDF5CellExtraction\"][\"image_size\"] = 100 # set back to a good default value for our dataset\n",
    "\n",
    "normalize_output = [False, True]\n",
    "for normalization in normalize_output:\n",
    "    project.config[\"HDF5CellExtraction\"][\"normalize_output\"] = normalization\n",
    "    project._update_extraction_f(HDF5CellExtraction)\n",
    "    project.extract(partial=True, n_cells=2, seed = 92)\n",
    "\n",
    "    fig = project.plot_single_cell_images(cell_ids=[80, 105], return_fig=True)\n",
    "    fig.suptitle(f\"Normalization: {normalization}\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization Range\n",
    "\n",
    "When choosing the second method you can further specify how the per-cell normalization should be performed by providing quantiles to calculate the min and max values to rescale your data to via the parameter `normalization_range`.\n",
    "\n",
    "This range per default is set to `(0.01, 0.99)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_ranges = [(0, 1), (0.001, 0.999), (0.01, 0.99), (0.1, 0.9)]\n",
    "for normalization_range in normalization_ranges:\n",
    "    project.config[\"HDF5CellExtraction\"][\"normalization_range\"] = normalization_range\n",
    "    project._update_extraction_f(HDF5CellExtraction)\n",
    "    project.extract(partial=True, n_cells=2, seed = 92)\n",
    "\n",
    "    fig = project.plot_single_cell_images(cell_ids=[80, 105], return_fig=True)\n",
    "    fig.suptitle(f\"Normalization Range: {normalization_range}\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scportrait_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
