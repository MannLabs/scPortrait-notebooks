{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook showcasing the different segmentation workflows\n",
    "\n",
    "This notebook walks you through the different segmentation workflows currently implemented in scPortrait using the same input example. Each segmentation workflow needs to be implemented in a seperate scPortrait project as the segmentation mask is the starting point for all further downstream steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "\n",
    "from scportrait.data._datasets import dataset_3\n",
    "from scportrait.pipeline.extraction import HDF5CellExtraction\n",
    "from scportrait.pipeline.project import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input images\n",
    "path = dataset_3()\n",
    "images = [\n",
    "    f\"{path}/Ch1.tif\",\n",
    "    f\"{path}/Ch2.tif\",\n",
    "    f\"{path}/Ch3.tif\",\n",
    "]\n",
    "\n",
    "project_directory = \"../example_projects/example_3/segmentation_workflows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize input images as example\n",
    "# it is not recommended to execute this block with large input images as it will compute for some time\n",
    "\n",
    "# read input image to visualize as an example\n",
    "image = np.array([tifffile.imread(img) for img in images])\n",
    "\n",
    "\n",
    "def colorize(im, color, clip_percentile=0.0):\n",
    "    \"\"\"\n",
    "    Helper function to create an RGB image from a single-channel image using a\n",
    "    specific color.\n",
    "    \"\"\"\n",
    "    # Check that we do just have a 2D image\n",
    "    if im.ndim > 2 and im.shape[2] != 1:\n",
    "        raise ValueError(\"This function expects a single-channel image!\")\n",
    "\n",
    "    # Rescale the image according to how we want to display it\n",
    "    im_scaled = im.astype(np.float32) - np.percentile(im, clip_percentile)\n",
    "    im_scaled = im_scaled / np.percentile(im_scaled, 100 - clip_percentile)\n",
    "    im_scaled = np.clip(im_scaled, 0, 1)\n",
    "\n",
    "    # Need to make sure we have a channels dimension for the multiplication to work\n",
    "    im_scaled = np.atleast_3d(im_scaled)\n",
    "\n",
    "    # Reshape the color (here, we assume channels last)\n",
    "    color = np.asarray(color).reshape((1, 1, -1))\n",
    "    return im_scaled * color\n",
    "\n",
    "\n",
    "def generate_composite(images, colors=None, plot=False):\n",
    "    if colors is None:\n",
    "        colors = [(0, 0, 1), (0, 1, 0), (1, 0, 0), (1, 0, 1)]\n",
    "    colorized = []\n",
    "    for image, color in zip(images, colors, strict=False):\n",
    "        image = colorize(image, color, 0.0)\n",
    "        colorized.append(image)\n",
    "\n",
    "    if plot:\n",
    "        for i in colorized:\n",
    "            plt.figure()\n",
    "            plt.imshow(i)\n",
    "\n",
    "    image = colorized[0]\n",
    "    for i in range(len(colorized) - 1):\n",
    "        image += colorized[i + 1]\n",
    "\n",
    "    return np.clip(image, 0, 1)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "for i, _img in enumerate(image):\n",
    "    axs[i].imshow(_img, cmap=\"gray\")\n",
    "    axs[i].axis(\"off\")\n",
    "    axs[i].set_title(f\"Channel {i+1}\")\n",
    "\n",
    "# also plot and visualize input image\n",
    "img = generate_composite(image)\n",
    "\n",
    "axs[3].imshow(img)\n",
    "axs[3].axis(\"off\")\n",
    "axs[3].set_title(\"Composite image\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGA Segmentation\n",
    "\n",
    "This segmentation workflow aims to segment mononucleated cells. Based on a nuclear and cytosolic stain, it first uses a thresholding approach to identify nuclei which are assumed to be the center of each cell. Then in a second step, the center of the identified nuclei are used as a starting point to generate a potential map using the cytosolic stain. This potential map is then used to segment the cytosol using a watershed approach. At the end of the workflow the user obtains both a nuclear and a cytosolic segmentation mask where each cytosol is matched to exactly one nucleus as kann be identified by the matching ``cell id``. \n",
    "\n",
    "The configuration file for the WGASegmentation method contains many parameters that need to be optimized for your particular dataset. Here is an example configuration:\n",
    "\n",
    "    WGASegmentation:\n",
    "    input_channels: 3\n",
    "    chunk_size: 50 # chunk size for chunked HDF5 storage. is needed for correct caching and high performance reading. should be left at 50.\n",
    "    cache: \".\"\n",
    "    lower_quantile_normalization:   0.001\n",
    "    upper_quantile_normalization:   0.999\n",
    "    median_filter_size:   4 # Size in pixels\n",
    "    nucleus_segmentation:\n",
    "        lower_quantile_normalization:   0.01 # quantile normalization of dapi channel before local tresholding. Strong normalization (0.05,0.95) can help with nuclear speckles.\n",
    "        upper_quantile_normalization:   0.99 # quantile normalization of dapi channel before local tresholding. Strong normalization (0.05,0.95) can help with nuclear speckles.\n",
    "        median_block: 41 # Size of pixel disk used for median, should be uneven\n",
    "        median_step: 4\n",
    "        threshold: 0.2 # threshold above local median for nuclear segmentation\n",
    "        speckle_kernel: 9 # Erosion followed by Dilation to remove speckels, size in pixels, should be uneven\n",
    "        peak_footprint: 7 # \n",
    "        min_distance: 8 # minimum distance between two nucleis in pixel\n",
    "        dilation: 0 # final dilation of pixel mask       \n",
    "        min_size: 200 # minimum nucleus area in pixel\n",
    "        max_size: 5000 # maximum nucleus area in pixel\n",
    "        contact_filter: 0.5 # minimum nucleus contact with background\n",
    "    cytosol_segmentation:\n",
    "        threshold: 0.15 # treshold above which cytosol is detected\n",
    "        lower_quantile_normalization: 0.01\n",
    "        upper_quantile_normalization: 0.99\n",
    "        erosion: 2 # erosion and dilation are used for speckle removal and shrinking / dilation\n",
    "        dilation: 7 # for no change in size choose erosion = dilation, for larger cells increase the mask erosion\n",
    "        min_clip: 0\n",
    "        max_clip: 0.2\n",
    "        min_size: 200\n",
    "        max_size: 30000\n",
    "    chunk_size: 50\n",
    "    filter_masks_size: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scportrait.pipeline.segmentation.workflows import WGASegmentation\n",
    "\n",
    "project_location = f\"{project_directory}/WGASegmentation\"\n",
    "\n",
    "project = Project(\n",
    "    os.path.abspath(project_location),\n",
    "    config_path=\"../example_projects/example_3/config_example3.yml\",\n",
    "    overwrite=True,\n",
    "    debug=False,\n",
    "    segmentation_f=WGASegmentation,\n",
    "    extraction_f=HDF5CellExtraction,\n",
    ")\n",
    "\n",
    "\n",
    "project.load_input_from_tif_files(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.segment()\n",
    "project.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(project.sdata[\"seg_all_nucleus\"])\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].set_title(\"Nucleus Segmentation Mask\")\n",
    "\n",
    "axs[1].imshow(project.sdata[\"seg_all_cytosol\"])\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].set_title(\"Cytosol Segmentation Mask\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f\"{project_location}/extraction/data/single_cells.h5\") as hf:\n",
    "    index = hf.get(\"single_cell_index\")\n",
    "    _images = hf.get(\"single_cell_data\")\n",
    "\n",
    "    n_cells = 4\n",
    "    fig, axs = plt.subplots(n_cells, 5, figsize=(5 * 2, n_cells * 2))\n",
    "    labels = [\"nucleus mask\", \"cytosol mask\", \"nucleus\", \"cytosol\", \"additional channel\"]\n",
    "\n",
    "    for i in range(n_cells):\n",
    "        cell_id = index[i][1]\n",
    "        image = _images[i]\n",
    "\n",
    "        for n, _img in enumerate(image):\n",
    "            axs[i, n].imshow(_img)\n",
    "\n",
    "            if n == 0:\n",
    "                axs[i, n].set_ylabel(f\"cell {cell_id}\", fontsize=10, rotation=0, labelpad=25)\n",
    "                axs[i, n].xaxis.set_visible(False)\n",
    "                axs[i, n].tick_params(left=False, labelleft=False)\n",
    "            else:\n",
    "                axs[i, n].axis(\"off\")\n",
    "\n",
    "            if i == 0:\n",
    "                axs[i, n].set_title(labels[n], fontsize=10)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAPI Segmentation\n",
    "\n",
    "This segmentation workflow aims to only segment the nuclei of cells. It uses the same nuclear segmentation method as the WGASegmentation. Here is an example configuration:\n",
    "\n",
    "    DAPISegmentation:\n",
    "        input_channels: 3\n",
    "        chunk_size: 50 # chunk size for chunked HDF5 storage. is needed for correct caching and high performance reading. should be left at 50.\n",
    "        cache: \".\"\n",
    "        lower_quantile_normalization:   0.001\n",
    "        upper_quantile_normalization:   0.999\n",
    "        median_filter_size:   4 # Size in pixels\n",
    "        nucleus_segmentation:\n",
    "            lower_quantile_normalization:   0.01 # quantile normalization of dapi channel before local tresholding. Strong normalization (0.05,0.95) can help with nuclear speckles.\n",
    "            upper_quantile_normalization:   0.99 # quantile normalization of dapi channel before local tresholding. Strong normalization (0.05,0.95) can help with nuclear speckles.\n",
    "            median_block: 41 # Size of pixel disk used for median, should be uneven\n",
    "            median_step: 4\n",
    "            threshold: 0.2 # threshold above local median for nuclear segmentation\n",
    "            min_distance: 8 # minimum distance between two nucleis in pixel\n",
    "            peak_footprint: 7 # \n",
    "            speckle_kernel: 9 # Erosion followed by Dilation to remove speckels, size in pixels, should be uneven\n",
    "            dilation: 0 # final dilation of pixel mask       \n",
    "            min_size: 200 # minimum nucleus area in pixel\n",
    "            max_size: 5000 # maximum nucleus area in pixel\n",
    "            contact_filter: 0.5 # minimum nucleus contact with background\n",
    "        chunk_size: 50\n",
    "        filter_masks_size: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scportrait.pipeline.segmentation.workflows import DAPISegmentation\n",
    "\n",
    "project_location = f\"{project_directory}/DAPISegmentation\"\n",
    "\n",
    "project = Project(\n",
    "    os.path.abspath(project_location),\n",
    "    config_path=\"../example_projects/example_3/config_example3.yml\",\n",
    "    overwrite=True,\n",
    "    debug=False,\n",
    "    segmentation_f=DAPISegmentation,\n",
    "    extraction_f=HDF5CellExtraction,\n",
    ")\n",
    "\n",
    "project.load_input_from_tif_files(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.segment()\n",
    "project.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "axs.imshow(project.sdata[\"seg_all_nucleus\"])\n",
    "axs.axis(\"off\")\n",
    "axs.set_title(\"Nucleus Segmentation Mask\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f\"{project_location}/extraction/data/single_cells.h5\") as hf:\n",
    "    index = hf.get(\"single_cell_index\")\n",
    "    _images = hf.get(\"single_cell_data\")\n",
    "\n",
    "    n_cells = 4\n",
    "    fig, axs = plt.subplots(n_cells, 4, figsize=(5 * 2, n_cells * 2))\n",
    "    labels = [\"nucleus mask\", \"duplicated nucleus mask\", \"nucleus\", \"cytosol\", \"additional channel\"]\n",
    "\n",
    "    for i in range(n_cells):\n",
    "        cell_id = index[i][1]\n",
    "        image = _images[i]\n",
    "\n",
    "        for n, _img in enumerate(image):\n",
    "            axs[i, n].imshow(_img)\n",
    "\n",
    "            if n == 0:\n",
    "                axs[i, n].set_ylabel(f\"cell {cell_id}\", fontsize=10, rotation=0, labelpad=25)\n",
    "                axs[i, n].xaxis.set_visible(False)\n",
    "                axs[i, n].tick_params(left=False, labelleft=False)\n",
    "            else:\n",
    "                axs[i, n].axis(\"off\")\n",
    "\n",
    "            if i == 0:\n",
    "                axs[i, n].set_title(labels[n], fontsize=10)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cytosol Segmentation Cellpose\n",
    "\n",
    "This method uses a deep learning based segmentation approach and should optimally be run using a GPU as it is otherwise very slow. During this segmentation workflow two different cellpose models are run. The first is used to segment the nuclei and the second one is used to segment the cytosols. Afterwards the IDs in the nucleus and cytosol mask are matched together.\n",
    "\n",
    "Here is an example configuration:\n",
    "\n",
    "    CytosolSegmentationCellpose:\n",
    "        input_channels: 2\n",
    "        output_masks: 2\n",
    "        shard_size: 120000000 # maxmimum number of pixel per tile\n",
    "        overlap_px: 100\n",
    "        nGPUs: 1\n",
    "        chunk_size: 50 # chunk size for chunked HDF5 storage. is needed for correct caching and high performance reading. should be left at 50.\n",
    "        threads: 1 # number of shards / tiles segmented at the same size. should be adapted to the maximum amount allowed by memory.\n",
    "        cache: \".\"\n",
    "        lower_quantile_normalization:   0.001\n",
    "        upper_quantile_normalization:   0.999\n",
    "        median_filter_size: 6 # Size in pixels\n",
    "        nucleus_segmentation:\n",
    "            model: \"nuclei\"\n",
    "        cytosol_segmentation:\n",
    "            model: \"cyto2\"\n",
    "        chunk_size: 50\n",
    "        match_masks: True\n",
    "        filtering_threshold_mask_matching: 0.95\n",
    "        filter_masks_size: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scportrait.pipeline.segmentation.workflows import CytosolSegmentationCellpose\n",
    "\n",
    "project_location = f\"{project_directory}/CytosolSegmentationCellpose\"\n",
    "\n",
    "project = Project(\n",
    "    os.path.abspath(project_location),\n",
    "    config_path=\"../example_projects/example_3/config_example3.yml\",\n",
    "    overwrite=True,\n",
    "    debug=False,\n",
    "    segmentation_f=CytosolSegmentationCellpose,\n",
    "    extraction_f=HDF5CellExtraction,\n",
    ")\n",
    "\n",
    "project.load_input_from_tif_files(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.segment()\n",
    "project.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(project.sdata[\"seg_all_nucleus\"])\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].set_title(\"Nucleus Segmentation Mask\")\n",
    "\n",
    "axs[1].imshow(project.sdata[\"seg_all_cytosol\"])\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].set_title(\"Cytosol Segmentation Mask\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f\"{project_location}/extraction/data/single_cells.h5\") as hf:\n",
    "    index = hf.get(\"single_cell_index\")\n",
    "    _images = hf.get(\"single_cell_data\")\n",
    "\n",
    "    n_cells = 4\n",
    "    fig, axs = plt.subplots(n_cells, 5, figsize=(5 * 2, n_cells * 2))\n",
    "    labels = [\"nucleus mask\", \"cytosol mask\", \"nucleus\", \"cytosol\", \"additional channel\"]\n",
    "\n",
    "    for i in range(n_cells):\n",
    "        cell_id = index[i][1]\n",
    "        image = _images[i]\n",
    "\n",
    "        for n, _img in enumerate(image):\n",
    "            axs[i, n].imshow(_img)\n",
    "\n",
    "            if n == 0:\n",
    "                axs[i, n].set_ylabel(f\"cell {cell_id}\", fontsize=10, rotation=0, labelpad=25)\n",
    "                axs[i, n].xaxis.set_visible(False)\n",
    "                axs[i, n].tick_params(left=False, labelleft=False)\n",
    "            else:\n",
    "                axs[i, n].axis(\"off\")\n",
    "\n",
    "            if i == 0:\n",
    "                axs[i, n].set_title(labels[n], fontsize=10)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAPI Segmentation Cellpose\n",
    "\n",
    "This method uses a deep learning based segmentation approach and should optimally be run using a GPU as it is otherwise very slow. It only performs a nuclear segmentation using one cellpose model. \n",
    "\n",
    "Here is an example configuration:\n",
    "\n",
    "    DAPISegmentationCellpose:\n",
    "        input_channels: 2\n",
    "        output_masks: 2\n",
    "        shard_size: 120000000 # maxmimum number of pixel per tile\n",
    "        overlap_px: 100\n",
    "        nGPUs: 1\n",
    "        chunk_size: 50 # chunk size for chunked HDF5 storage. is needed for correct caching and high performance reading. should be left at 50.\n",
    "        threads: 1 # number of shards / tiles segmented at the same size. should be adapted to the maximum amount allowed by memory.\n",
    "        cache: \".\"\n",
    "        lower_quantile_normalization:   0.001\n",
    "        upper_quantile_normalization:   0.999\n",
    "        median_filter_size: 6 # Size in pixels\n",
    "        nucleus_segmentation:\n",
    "            model: \"nuclei\"\n",
    "        chunk_size: 50\n",
    "        filter_masks_size: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scportrait.pipeline.segmentation.workflows import DAPISegmentationCellpose\n",
    "\n",
    "project_location = f\"{project_directory}/DAPISegmentationCellpose\"\n",
    "\n",
    "project = Project(\n",
    "    os.path.abspath(project_location),\n",
    "    config_path=\"../example_projects/example_3/config_example3.yml\",\n",
    "    overwrite=True,\n",
    "    debug=False,\n",
    "    segmentation_f=DAPISegmentationCellpose,\n",
    "    extraction_f=HDF5CellExtraction,\n",
    ")\n",
    "\n",
    "project.load_input_from_tif_files(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.segment()\n",
    "project.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "axs.imshow(project.sdata[\"seg_all_nucleus\"])\n",
    "axs.axis(\"off\")\n",
    "axs.set_title(\"Nucleus Segmentation Mask\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f\"{project_location}/extraction/data/single_cells.h5\") as hf:\n",
    "    index = hf.get(\"single_cell_index\")\n",
    "    images = hf.get(\"single_cell_data\")\n",
    "\n",
    "    n_cells = 4\n",
    "    fig, axs = plt.subplots(n_cells, 4, figsize=(4 * 2, n_cells * 2))\n",
    "    labels = [\"nucleus mask\", \"cytosol mask\", \"nucleus\", \"cytosol\", \"additional channel\"]\n",
    "\n",
    "    for i in range(n_cells):\n",
    "        cell_id = index[i][1]\n",
    "        image = images[i]\n",
    "\n",
    "        for n, _img in enumerate(image):\n",
    "            axs[i, n].imshow(_img)\n",
    "\n",
    "            if n == 0:\n",
    "                axs[i, n].set_ylabel(f\"cell {cell_id}\", fontsize=10, rotation=0, labelpad=25)\n",
    "                axs[i, n].xaxis.set_visible(False)\n",
    "                axs[i, n].tick_params(left=False, labelleft=False)\n",
    "            else:\n",
    "                axs[i, n].axis(\"off\")\n",
    "\n",
    "            if i == 0:\n",
    "                axs[i, n].set_title(labels[n], fontsize=10)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scPortrait",
   "language": "python",
   "name": "scportrait"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
